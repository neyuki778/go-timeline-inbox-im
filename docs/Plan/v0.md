## 设计要点总结

### 核心设计原则
- **分阶段递进**：先 Make it Work，再 Make it Scale
- **模型选型**：读扩散适合群聊，写扩散适合单聊
- **离线漫游**：用 `seq` 做断点续传，是现代 IM 的标配

### 开发环境配置

详见 [DEV_SETUP.md](../DEV_SETUP.md)，一键启动：

```bash
# 启动 MySQL + Redis
docker-compose up -d

# 验证
docker exec -it go-im-mysql mysql -u im_user -pim_pass123 -e "USE go_im; SHOW TABLES;"
```

| 服务 | Host | Port | 用户名 | 密码 |
|------|------|------|--------|------|
| MySQL | localhost | 3306 | im_user | im_pass123 |
| Redis | localhost | 6379 | - | - |

### 关键改进点

| 优先级 | 改进项 | 阶段 | 说明 |
|--------|--------|------|------|
| 🔴 高 | 会话内 `seq` + 复合唯一索引 | 阶段一 | 解决多会话共享自增ID导致的漏拉/误拉问题 |
| 🔴 高 | 增加 `msg_id` 幂等字段 | 阶段一 | 客户端重试发送时防止消息重复 |
| 🔴 高 | ACK 按会话维度存储 | 阶段一 | 新增 `user_conversation_state` 表，支持多会话独立确认 |
| 🟡 中 | 分页拉取改为游标模式 | 阶段一 | 用 `cursor_seq` 替代 OFFSET，避免翻页重复/遗漏 |
| 🟡 中 | 心跳超时逻辑明确 | 阶段一 | 间隔 30s，连续 2-3 次无心跳视为离线 |
| 🟡 中 | content 字段加长度限制 | 阶段一 | VARCHAR(4096) 或应用层校验，防止超大消息 |
| 🟢 低 | Redis 过期策略 | 阶段二 | 防止 Inbox 无限增长 |
| 🟢 低 | Kafka 分区策略 | 阶段三 | 按 `conversation_id` Hash 保证消息顺序 |

---

### 第一阶段：单机 MVP (最小可行性产品)

**目标**：跑通基于 MySQL 的“读扩散”模型。实现群聊、发消息、**离线消息拉取**。

#### Step 1: 工程搭建与数据库设计

不要急着写 Go，先设计“图纸”, 把数据结构定义好。

1.  **建立 Go 项目结构** (遵循 `golang-standards`):

    ```text
    /cmd/server/main.go      // 入口
    /internal/service        // 业务逻辑
    /internal/repository     // 数据库操作 (DAO)
    /internal/model          // 结构体定义
    /pkg/protocol            // 协议定义
    /configs                 // 配置文件
    ```

2.  **MySQL 建表 (核心任务)**:
    需要四张表。

    ```sql
    -- 1. 消息表 (Timeline 的载体)
    CREATE TABLE `timeline_message` (
        `id` BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
        `msg_id` VARCHAR(64) NOT NULL,          -- 客户端生成的唯一ID，用于幂等去重
        `conversation_id` VARCHAR(64) NOT NULL, -- 会话ID，如 "group_101" 或 "private_u1_u2"
        `seq` BIGINT UNSIGNED NOT NULL,         -- ⭐ 会话内序列号（核心字段）
        `sender_id` VARCHAR(64) NOT NULL,       -- 发送者ID
        `content` VARCHAR(4096),                -- 消息内容（限制长度，防止超大消息）
        `msg_type` TINYINT DEFAULT 1,           -- 1:文本, 2:图片
        `status` TINYINT DEFAULT 0,             -- 0:发送中, 1:已送达, 2:已读
        `send_time` BIGINT NOT NULL,            -- 发送时间戳
        `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        UNIQUE INDEX `uk_msg_id` (`msg_id`),                    -- 幂等去重索引
        UNIQUE INDEX `uk_conv_seq` (`conversation_id`, `seq`),  -- ⭐ 核心：保证会话内seq唯一
        INDEX `idx_conv_seq` (`conversation_id`, `seq`)         -- ⭐ 核心：用于范围拉取
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

    -- 2. 用户表
    CREATE TABLE `user` (
        `id` BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY,
        `user_id` VARCHAR(64) NOT NULL UNIQUE,
        `nickname` VARCHAR(64),
        `created_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

    -- 3. 用户会话状态表 (⭐ 按会话维度存储ACK位点)
    CREATE TABLE `user_conversation_state` (
        `user_id` VARCHAR(64) NOT NULL,
        `conversation_id` VARCHAR(64) NOT NULL,
        `last_ack_seq` BIGINT UNSIGNED DEFAULT 0,  -- 用户在该会话的最后确认序号
        `updated_at` TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
        PRIMARY KEY (`user_id`, `conversation_id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

    -- 4. 群成员表 (预留，第一阶段可先写死 group_1)
    CREATE TABLE `group_member` (
        `group_id` VARCHAR(64) NOT NULL,
        `user_id` VARCHAR(64) NOT NULL,
        `join_time` BIGINT NOT NULL,
        PRIMARY KEY (`group_id`, `user_id`)
    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
    ```

    **⚠️ Seq 生成策略（阶段一简化版）**:
    ```go
    // 单机版：查询当前会话最大seq后+1（事务内执行，保证原子性）
    // SELECT COALESCE(MAX(seq), 0) + 1 FROM timeline_message WHERE conversation_id = ?
    // 阶段二改用 Redis INCR 提升性能
    ```

#### Step 2: 协议定义与 WebSocket 握手

利用 WebSocket 建立长连接。

1.  **定义通信协议 (`internal/model/protocol.go`)**:
    不要只发字符串，要定义标准的 JSON 结构。
    ```go
    // 客户端发给服务器的包
    type CmdType int
    const (
        CmdHeartbeat CmdType = 0 // 心跳
        CmdLogin     CmdType = 1 // 登录
        CmdChat      CmdType = 2 // 发送消息
        CmdPull      CmdType = 3 // 核心：主动拉取消息
        CmdAck       CmdType = 4 // 消息确认
    )

    type InputPacket struct {
        Cmd            CmdType         `json:"cmd"`
        MsgId          string          `json:"msg_id,omitempty"`          // 客户端生成的消息唯一ID (幂等)
        ConversationId string          `json:"conversation_id,omitempty"` // 会话ID
        CursorSeq      int64           `json:"cursor_seq,omitempty"`      // ⭐ 游标：从该seq之后开始拉取
        Payload        json.RawMessage `json:"payload,omitempty"`         // 具体数据
    }

    // 服务端发给客户端的包
    type OutputPacket struct {
        Cmd           CmdType     `json:"cmd"`
        Code          int         `json:"code"`                        // 0:成功, 非0:失败
        MsgId         string      `json:"msg_id,omitempty"`            // 对应请求的消息ID
        Seq           int64       `json:"seq,omitempty"`               // 服务端分配的序列号
        NextCursorSeq int64       `json:"next_cursor_seq,omitempty"`   // ⭐ 下次拉取的游标
        HasMore       bool        `json:"has_more,omitempty"`          // ⭐ 是否还有更多消息
        Payload       interface{} `json:"payload,omitempty"`
    }
    ```

2.  **心跳机制设计**:
      * **心跳间隔**：客户端每 30 秒发送一次 `CmdHeartbeat`
      * **超时判断**：服务端连续 2-3 次（60-90s）未收到心跳，判定为离线
      * **方式**：客户端主动发送，服务端被动接收并更新在线状态

3.  **实现 WebSocket 接入 (`cmd/server/main.go`)**:
      * 使用 `github.com/gorilla/websocket`。
      * 写一个 `ConnectionManager` (连接管理器)，用一个 `map[string]*websocket.Conn` 存所有在线连接。
      * **难点**：Go 的 Map 不是并发安全的，需要用 `sync.RWMutex` 保护这个 Map。

#### Step 3: 实现“先存储”

这是 Timeline 模型的第一步。

1.  **接收消息逻辑**:
      * 解析 WebSocket 传来的 `CmdChat` 包。
      * 提取 `conversation_id` 和 `content`。
2.  **写入 MySQL**:
      * 使用 GORM 或 sqlx 写入 `timeline_message` 表。
      * **注意**：这里依赖 MySQL 的 `AUTO_INCREMENT` 生成消息 ID (SeqID)。

#### Step 4: 实现“后同步” —— 在线推送 (Push)

消息存进去了，现在要推给在线的人。

1.  **简单的广播逻辑**:
      * 假设大家都在 "group\_1" (为了简化)。
      * 遍历 `ConnectionManager` 里的 Map。
      * 把刚才存入 MySQL 的消息（带上生成的 ID），JSON 序列化后 `conn.WriteJSON()` 给所有人。

#### Step 5: 实现"后同步" —— 离线拉取

这是区分"玩具聊天室"和"现代 IM"的关键。

1.  **场景**: 用户断网了 10 分钟，重连。
2.  **客户端逻辑 (模拟)**: 发送 `CmdPull`，带上 `conversation_id` 和 `cursor_seq = 100`。
    ```json
    { "cmd": 3, "conversation_id": "group_1", "cursor_seq": 100 }
    ```
3.  **服务端逻辑**:
      * 收到 `CmdPull`。
      * 执行 SQL（⭐ 使用会话内 seq，而非全局 id）:
        ```sql
        SELECT * FROM timeline_message 
        WHERE conversation_id = ? AND seq > ? 
        ORDER BY seq ASC 
        LIMIT 50;
        ```
      * 返回消息列表 + 游标信息:
        ```json
        {
          "cmd": 3,
          "code": 0,
          "payload": [...],
          "next_cursor_seq": 150,
          "has_more": true
        }
        ```
4.  **ACK 更新**: 客户端收到消息后发送 `CmdAck`，服务端更新 `user_conversation_state` 表。

> **✅ 第一阶段验收标准**:
> 可以用两个浏览器窗口（或 Postman），A 发消息，B 断开连接再重连，B 能自动收到刚才 A 发的消息。

-----

### 第二阶段：引入 Redis 优化 (信箱模型)

**目标**：解决 MySQL 压力，实现 1v1 聊天的**写扩散**优化。

#### Step 1: 全局序列号生成器

MySQL 的自增 ID 在分库分表下会失效，且性能差。我们改用 Redis。

1.  **部署 Redis**: Docker 跑起来。
2.  **改造 ID 生成逻辑**:
      * 每当有新消息发往 `group_A`。
      * Go 代码调用 Redis: `INCR im:seq:group_A`。
      * 拿到返回的数字（比如 1001），把它作为 `seq_id` 写入 MySQL，不再依赖 MySQL 自增。

#### Step 2: 实现单聊的"信箱"

对于 1v1 聊天，我们不再查大表，而是读小队列。

1.  **数据结构**: 使用 Redis Sorted Set (`ZADD` / `ZRANGEBYSCORE`)，比 List 更灵活。
2.  **Key 设计**: `im:inbox:{user_id}`。
3.  **发送逻辑改造**:
      * A 给 B 发消息。
      * 1.  存 MySQL 全量表 (归档用)。
      * 2.  **同时** 用 `ZADD im:inbox:B <seq_id> <msg_json>` 写入 Redis。
4.  **接收逻辑改造**:
      * B 在线时，直接推。
      * B 离线重连时，直接从 Redis `ZRANGEBYSCORE im:inbox:B <last_seq> +inf` 取数据，速度极快。
5.  **⚠️ 过期策略 (重要)**:
      * 方案一：设置 Key TTL，`EXPIRE im:inbox:B 604800` (7天)
      * 方案二：定期任务清理，`ZREMRANGEBYSCORE im:inbox:B -inf <threshold_seq>`
      * 方案三：限制条数，`ZREMRANGEBYRANK im:inbox:B 0 -1001` (只保留最新1000条)

> **✅ 第二阶段验收标准**:
> 查看 Redis Desktop Manager，发消息时能看到 Redis 里对应的 Key 在自增，Sorted Set 里有数据。

-----

### 第三阶段：架构解耦 (引入 RabbitMQ)

**目标**：削峰填谷，防止数据库被瞬间流量打爆。

#### 为什么选 RabbitMQ 而不是 Kafka？

| 对比项 | RabbitMQ | Kafka |
|--------|----------|-------|
| 学习曲线 | 🟢 低，概念简单 | 🔴 高，需理解分区、消费组 |
| 部署复杂度 | 🟢 单容器即可 | 🔴 需要 Zookeeper |
| 适用场景 | 任务队列、解耦 | 日志流、大数据 |
| 消息量级 | 万级 QPS | 百万级 QPS |

**结论**：对于学习项目和中小规模 IM，RabbitMQ 足够且更易上手。

#### Step 1: 生产者改造 (Gateway)

1.  **部署 RabbitMQ**: 取消 `docker-compose.yml` 中 rabbitmq 的注释，然后 `docker-compose up -d`。
2.  **管理界面**: 访问 http://localhost:15672 (用户名/密码: im_user/im_pass123)
3.  **队列设计**:
      * Exchange: `im.direct` (Direct 类型)
      * Queue: `im.msg.process`
      * Routing Key: `msg.send`
4.  **修改发送接口**:
      * 收到 WebSocket 消息后，**不再**直接写 MySQL/Redis。
      * 而是封装成一个 Event (JSON)，发布到 RabbitMQ。
      * **立即返回** 客户端 "已发送" (Ack)。
      ```go
      // 发布消息到 RabbitMQ
      ch.Publish(
          "im.direct",  // exchange
          "msg.send",   // routing key
          false, false,
          amqp.Publishing{
              ContentType: "application/json",
              Body:        msgJSON,
          },
      )
      ```

#### Step 2: 消费者开发 (Worker)

1.  **新建一个 Go 程序 (或者在同一个程序里开 Goroutine)**:
      * 监听 RabbitMQ 队列 `im.msg.process`。
      ```go
      msgs, _ := ch.Consume("im.msg.process", "", false, false, false, false, nil)
      for msg := range msgs {
          // 处理消息
          processMessage(msg.Body)
          msg.Ack(false) // 手动确认
      }
      ```
2.  **搬运逻辑**:
      * 收到消息 -\> 获取 Redis Seq ID -\> 写 MySQL -\> 写 Redis Inbox -\> 触发 WebSocket 推送。

#### Step 3: 优雅的推送 (可选)

  * 如果 Consumer 和 Gateway 是分离的（微服务），Consumer 处理完消息后，需要通知 Gateway 推送。
  * **简单做法**：Consumer 处理完，把消息再发到 Redis Pub/Sub，Gateway 订阅 Redis，收到通知后推给用户。

> **✅ 第三阶段验收标准**:
> Gateway 负责接入，RabbitMQ 负责缓冲，Worker 负责落库。可在 RabbitMQ 管理界面看到消息流转。

---

### 未来优化方向

以下功能超出 MVP 范围，但了解其存在可以展示技术视野：

| 方向 | 说明 | 复杂度 |
|------|------|--------|
| 🔐 基础鉴权 (收尾阶段) | JWT Token 验证，防止伪造 user_id | 低 |
| 协议版本兼容 | cmd 扩展、字段必选/可选、错误码约定，防止旧客户端解析失败 | 中 |
| 群成员/权限模型 | 入群/退群、拉黑、禁言等写路径和幂等校验 | 高 |
| 大群读写扩散切换 | 小群用写扩散，大群（>500人）切换为读扩散 | 高 |
| 消息补洞策略 | 检测 seq 不连续时主动补拉缺失消息 | 中 |
| 大文件/图片处理 | CDN 上传、秒传、缩略图、内容安全审核 | 高 |
| 监控与可观测性 | trace_id/req_id、Prometheus 指标、告警 | 中 |
| 限流与背压 | 网关限流、消费者背压、死信队列 | 中 |

---

### 外部依赖包总结

项目中用到的 Go 第三方库：

#### 阶段一（必需）

| 包名 | 用途 | 安装命令 |
|------|------|----------|
| `github.com/gorilla/websocket` | WebSocket 长连接 | `go get github.com/gorilla/websocket` |
| `gorm.io/gorm` | ORM 框架 | `go get gorm.io/gorm` |
| `gorm.io/driver/mysql` | GORM MySQL 驱动 | `go get gorm.io/driver/mysql` |
| `github.com/google/uuid` | 生成 msg_id | `go get github.com/google/uuid` |

#### 阶段二（Redis）

| 包名 | 用途 | 安装命令 |
|------|------|----------|
| `github.com/redis/go-redis/v9` | Redis 客户端 | `go get github.com/redis/go-redis/v9` |

#### 阶段三（RabbitMQ）

| 包名 | 用途 | 安装命令 |
|------|------|----------|
| `github.com/rabbitmq/amqp091-go` | RabbitMQ 客户端 | `go get github.com/rabbitmq/amqp091-go` |

#### 收尾阶段（鉴权）

| 包名 | 用途 | 安装命令 |
|------|------|----------|
| `github.com/golang-jwt/jwt/v5` | JWT Token 生成与验证 | `go get github.com/golang-jwt/jwt/v5` |

#### 可选（提升开发体验）

| 包名 | 用途 | 安装命令 |
|------|------|----------|
| `github.com/spf13/viper` | 配置文件管理 | `go get github.com/spf13/viper` |
| `go.uber.org/zap` | 高性能日志库 | `go get go.uber.org/zap` |

#### 一键安装所有依赖

```bash
# 阶段一
go get github.com/gorilla/websocket
go get gorm.io/gorm gorm.io/driver/mysql
go get github.com/google/uuid

# 阶段二
go get github.com/redis/go-redis/v9

# 阶段三
go get github.com/rabbitmq/amqp091-go

# 收尾
go get github.com/golang-jwt/jwt/v5

# 可选
go get github.com/spf13/viper go.uber.org/zap
```

---

### 收尾阶段：基础鉴权

**目标**：防止伪造 user_id。

#### 简易方案（推荐）

1. **登录接口** (`POST /api/login`):
   ```go
   // 请求
   { "user_id": "user_1", "password": "123456" }
   
   // 响应 (返回 JWT Token)
   { "token": "eyJhbGciOiJIUzI1NiIs..." }
   ```

2. **WebSocket 握手时验证**:
   ```go
   // 连接 URL 带 token
   ws://localhost:8080/ws?token=eyJhbGciOiJIUzI1NiIs...
   
   // 服务端验证
   func (s *Server) HandleWebSocket(w http.ResponseWriter, r *http.Request) {
       token := r.URL.Query().Get("token")
       claims, err := jwt.Parse(token, secretKey)
       if err != nil {
           http.Error(w, "Unauthorized", 401)
           return
       }
       userID := claims.UserID
       // ... 建立连接
   }
   ```

3. **依赖库**:
   ```bash
   go get github.com/golang-jwt/jwt/v5
   ```

> **💡 MVP 阶段**：可以先用 URL 参数传 user_id（`ws://localhost:8080/ws?user_id=xxx`），收尾时再改成 JWT。
